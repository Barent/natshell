# NatShell Configuration
# Copy to ~/.config/natshell/config.toml to customize

[model]
# Path to GGUF model file. "auto" triggers download of default model.
path = "auto"
# HuggingFace repo for auto-download
hf_repo = "Qwen/Qwen3-4B-GGUF"
hf_file = "Qwen3-4B-Q4_K_M.gguf"
# Context window size (tokens).
# 0 = auto: scales with model size (2048/4096/8192/16384/32768).
# Set explicitly to override (e.g. 8192, 16384).
n_ctx = 0
# Number of CPU threads (0 = auto-detect based on core count)
n_threads = 0
# GPU layers to offload (0 = CPU only, -1 = all layers to GPU)
n_gpu_layers = -1
# GPU device index (-1 = auto-detect best GPU, 0 = first device, etc.)
# Useful on multi-GPU systems to select the discrete GPU over an iGPU.
main_gpu = -1
# Enable RAM-based prompt caching for local inference.
# Caches tokenized prompts so repeated prefixes (e.g. system prompt) are faster.
# prompt_cache = true
# Maximum RAM to use for the prompt cache (megabytes).
# prompt_cache_mb = 256

[remote]
# Uncomment to use a remote OpenAI-compatible API instead of local model.
# When enabled, the local model is not loaded.
# url = "http://localhost:11434/v1"
# model = "qwen3:4b"
# api_key = ""
# Override the context window size for the remote model (tokens).
# 0 = auto: queries the running model's actual context from the server.
# Set explicitly if the server doesn't report context size correctly.
# n_ctx = 0

[ollama]
# Remote server URL (Ollama or any OpenAI-compatible API).
# Used by /model list and /model use commands.
# url = "http://localhost:11434"
# Default model for the remote server
# default_model = "qwen3:4b"

[agent]
# Maximum tool calls per user request (minimum floor).
# Auto-scales with context window: 15/25/35/50/60/75 for 4k/8k/16k/32k/128k/256k contexts.
max_steps = 15
# Temperature for generation — lower = more deterministic
temperature = 0.3
# Max tokens per model generation (minimum floor).
# Auto-scales to 25% of the context window (capped at 65536) when larger.
# Shell output truncation and file read limits also auto-scale with context:
#   Shell output: 4k/8k/12k/16k/32k/64k chars for 4k/16k/32k/64k/128k/256k contexts.
#   File read: 200/500/1000/2000/3000/4000 lines for <16k/16k/32k/64k/128k/256k contexts.
max_tokens = 2048
# Extra context tokens to reserve beyond max_tokens (0 = auto ~400 tokens).
# Increase if you add many custom safety patterns or use verbose tool outputs.
# context_reserve = 0

[safety]
# Safety mode:
#   "confirm"  = ask user before moderate/dangerous commands (recommended)
#   "warn"     = show warning but auto-execute
#   "yolo"     = execute everything without confirmation (dangerous!)
mode = "confirm"

# Commands that always require user confirmation (regex patterns matched against full command)
always_confirm = [
    "^rm\\s",
    "^sudo\\s",
    "^dd\\s",
    "^mkfs",
    "^shutdown",
    "^reboot",
    "^systemctl\\s+(stop|disable|mask|restart|enable|start)",
    "^chmod\\s+[0-7]*7",
    "^chown",
    "\\|\\s*tee\\s",
    ">\\s*/etc/",
    "^kill",
    "^wipefs",
    "^fdisk",
    "^parted",
    "^apt\\s+(install|remove|purge|autoremove)",
    "^dnf\\s+(install|remove|erase)",
    "^pacman\\s+-[SRU]",
    "^pip\\s+install",
    "^docker\\s+(rm|rmi|stop|kill|system\\s+prune)",
    "^iptables",
    "^ufw",
    "^crontab",
    "^brew\\s+(install|uninstall|remove|upgrade)",
    "^launchctl\\s+(load|unload|stop|start|bootout|bootstrap)",
]

# Commands that are blocked entirely — never executed
blocked = [
    ":(){ :|:& };:",
    "^rm\\s+-[rR]f\\s+/\\s*$",
    "^rm\\s+-[rR]f\\s+/\\*",
    "^mv\\s+/\\s",
    "^dd\\s+.*of=/dev/[sh]d[a-z]\\s*$",
    "^mkfs.*\\s/dev/[sh]d[a-z][0-9]?\\s*$",
    "> /dev/[sh]d[a-z]",
    "^diskutil\\s+eraseDisk",
]

[backup]
# Pre-edit file backup (supports /undo)
enabled = true
# Maximum backup copies to keep per file
max_per_file = 10

[ui]
# Theme: "dark" or "light"
theme = "dark"
